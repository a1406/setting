# others
next key locking 避免幻读

插入缓冲 insert buffer

二次写  double write

自适应哈希索引  adaptive hash index

预读  read ahead

show engine innodb status 可以看大量innodb的状态

# 2.3  innodb体系架构
## 线程
master thread 缓冲刷新：
脏页刷新  合并插入缓冲  undo页回收

io thread：
处理AIO的回调，一般是4个  read，write，insert buffer，log 

purge thread：
回收事务提交之后的undo log

page clean thread：
后来加入的，把原master thread的脏页刷新移到这里来

## 内存
缓存大小配置：
show variables like  'innodb_buffer_size';

缓存类型：
- 索引页
- 数据页
- undo页
- 插入缓冲 insert buffer
- 自适应哈希索引  adaptive hash index
- 锁信息  lock info
- 数据字典信息  data dict

此外还有重做日志缓冲
redo log_buffer

### 内存的lru算法
在lru的基础上，添加了midpoint位置（innodb_old_blocks_pct），只有在midpoint之下， 也就是old区域超过一定时间（innodb_old_blocks_time），才会加入lru的头部，这样可以避免大量的lru头部因为某个一次性的扫描被换出

### flush列表
LRU中的页被修改后，被称为脏页（dirty page），脏页同时也存在与flush列表。

### 重做日志缓冲（redo log buffer）
默认8M， 每秒master线程会刷新重做日志缓冲到磁盘，事务提交时也会刷新到磁盘，或者buffer小于一半时，也会刷新到磁盘

# 2.4 checkpoint技术
数据库宕机时，只需要重做日志恢复checkpoint之后的部分

如果LRP要移除脏页，那么需要强制checkpoint

## LSN（log seq number）
LSN是8字节数字，单位是字节，每个页有LSN，重做日志也有LSN，checkpoint也有LSN

# 2.6 innodb关键特性
## insert buffer
缓冲池中有insert buffer信息，同时，insert buffer和数据页一样，是物理页的一个部分

目的是为了提高非聚簇索引的插入效率（多个插入的索引可能在同一个索引页中）

使用需要两个条件

* 是辅助索引
* 不是唯一索引

问题是会占用大量缓冲池内存

### change buffer
可以视为insert buffer的升级, 依然是对非唯一辅助索引起作用

* insert => insert buffer
* update => purge buffer
* delete => delete buffer

### insert buffer的实现
所有表的辅助索引的insert buffer放在同一个B+树中，所以通过独立表空间的idb文件恢复表后，还需要repair table重建表上的辅助索引

## 两次写  double write
目的是为了提高可靠性

重做日志虽然可以恢复数据，但是重做日志记录的是物理变化，比如某个页偏移800写入A，所以，在使用重做日志前，需要一个可靠的数据页的副本。先通过副本恢复页，然后再执行重做日志。这就是double write。

double write分两部分，一部分是内存（doublewrite buffer），共2M。

另一部分是磁盘上的128个连续的页（16K一个），一共也是2M。

对缓冲池中的脏页进行刷新时，先memcpy到doublewrite buffer，再通过doublewrite buffer分两次，每次1M的写入磁盘，并立即fsync。这个过程是顺序写。 最后再把数据写入各个表的空间中去，这个过程是离散写。 

# 3.2 日志文件
## 错误日志
show variables like 'log_error'  定位错误文件位置

## 慢查询日志

## 查询日志

## 二进制日志（bin log）
记录的是所有更改的操作

* 恢复   例如回档
* 复制   例如主从同步
* 审计   例如检查是否有注入攻击

相关参数

* max_binlog_size  单个binlog文件最大大小，默认1G
* binlog_cache_size 所有未提交的事务的二进制日志会被记录到一个缓存中，提交时直接将该缓存写入binlog文件，该缓存大小由binlog_cache_size决定，默认32K
* sync_binlog 写多少次缓存就同步一次binlog文件。binlog写入发生在事务提交前，所以，即使这里设置成1，在宕机时，也可能发生事务未提交，但是binlog已经记录的情况。可以通过设置innodb_support_xa为1来避免这种情况
* binlog_format  
    * STATEMENT： 记录SQL语句，使用rand等函数会导致主从不一致，在读已提交模式下也会出现丢失更新导致主从不一致。
    * ROW： 记录行字段的变化，会增加binlog的大小
    * MIXED:  混合模式，大部分使用STATEMENT方式，部分使用ROW方式。

## 重做日志文件（redo log）
### 和binlog的区别
* 是innodb的日志文件，记录的是页更改的物理情况
* 写入时机不同，binlog是事务提交前写一次，而redolog在事务过程中不断地写入。

### 写入方式
先写入redo log buffer，然后再写入磁盘。

写入磁盘时，是按扇区大小（512字节）写入的，因为扇区是写入最小单位，可以保证成功，所以不需要double write

innodb_flush_log_at_trx_commit

* 0表示提交事务时，不刷新redo log到磁盘，可能导致宕机恢复时丢失事务
* 1表示事务提交时，同步刷新redo log到磁盘
* 2表示事务提交时，异步刷新redo log到磁盘

# 5.6 B+树索引的使用
## 5.6.2 联合索引
联合索引也是B+树组织的，但是是以第一个键来排序，所以对于第二个键的where条件未必能使用该索引

但是如果需要同时使用到第一和第二个键，有时候是有好处的，尤其是需要对第二个键排序的情况。

# 6.3 innodb中的锁
# 6.5 锁的问题
## 脏读
指的是读到未提交的内容，read uncommitted级别会有这种问题。

某些特殊情况下可以使用这种级别，比如从节点，并且在该节点的查询并不需要特别精确的值

## 不可重复读
一个事务中，因为别的事务的修改，导致两次或者多次读取到的数据内容不一样。也称作幻读。

innodb中，通过next-key lock算法，锁住一段范围来避免。（待测试）

## 丢失更新
一个事务的操作会被另外一个事务的操作覆盖。当前数据库因为有行锁表锁，理论上不会有该问题，但是用户程序的逻辑可能导致这种情况的发生。通过select for update之类的方式可以避免。

# 7.1 事务的特性
* A 原子性
* C 一致性
* I 隔离性
* D 持久性

# 7.2 事务的实现
* redo log， 物理日志，记录的是物理修改，是幂等的。
* undo log，逻辑日志，根据每行记录进行记录

## redo log
用来实现D（持久性），由两部分组成
* 内存中的重做日志缓冲（redo log buffer）
* 重做日志文件（redo log file）

## undo log
用来帮助事务回滚以及实现MVCC功能，所以undo log在事务提交时不能立即删除，因为可能有其他事务还需要之前的版本数据。

undo log 会伴随着redo log的产生，因为undo log也需要持久性

# 7.6 事务的隔离级别
* 读未提交 read uncommitted
* 读已提交 read committed
* 可重复读 repeateable read
* serializable

# 7.7 分布式事务
由于复制的需要，mysql内部的binlog和redo log也实现了分布式事务。

1. innodb prepare
2. binlog写入，并复制到salve
3. 写入redo log

？ 如果发生宕机，binlog在slave上重复执行，是否会有幂等的问题？
